{
  "metadata": {
    "name": "Hive Lab",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Hive Lab: Analyzing Sales Data with Hive on Google Dataproc\n\n## Objective: \n- To understand the basic concepts of Apache Hive, including creating tables, loading data and perform different aggregation operations on a sales data set using Google Dataproc cluster.\n\n## Prerequisites: \n- A Google Cloud Platform account with access to Dataproc.\n- Familiarity with the command line interface\n\n## Step 1: Create a Dataproc Cluster\n- Log in to your Google Cloud Platform account and navigate to the Dataproc dashboard.\n- Click on the \"Create cluster\" button to create a new cluster with the default settings.\n- SSH into the cluster\u0027s master node\n\n## Step 2: Download sales data\n- Use the command `wget https://raw.githubusercontent.com/tofighi/BigData/main/datasets/sales/sales_data.csv -P /var/tmp` to download the sales_data.csv file from the GitHub repository and save it in the /var/tmp directory\n- Verify that the file has been downloaded by running the command `ls /var/tmp/sales_data.csv`"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\nwget https://raw.githubusercontent.com/tofighi/BigData/main/datasets/sales/sales_data.csv -P /var/tmp\nls /var/tmp/sales_data.csv"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Step 3: Move the file to HDFS\n- Move the downloaded file to HDFS by using the command `hadoop fs -put /var/tmp/sales_data.csv /`\n- Verify that the file has been moved to HDFS by running the command `hadoop fs -ls /`\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\nhadoop fs -put /var/tmp/sales_data.csv /\nhadoop fs -ls /"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Step 4: Create a Hive database and table\n- Create a new database named \"sales_db\" by running the command `CREATE DATABASE sales_db;`\n- Use the database by running the command `USE sales_db;`\n- Create a new table named \"sales_data\" using the command `CREATE TABLE sales_data (order_id INT, city STRING, province STRING, product_name STRING, product_price FLOAT, quantity INT) ROW FORMAT DELIMITED FIELDS TERMINATED BY \u0027,\u0027 tblproperties(\"skip.header.line.count\"\u003d\"1\");`\n- Load the data from the \"sales_data.csv\" file into the table by running the command `LOAD DATA INPATH \u0027/sales_data.csv\u0027 INTO TABLE sales_data;`"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nCREATE DATABASE sales_db;\nUSE sales_db;\nCREATE TABLE sales_data (order_id INT, city STRING, province STRING, product_name STRING, product_price FLOAT, quantity INT) ROW FORMAT DELIMITED FIELDS TERMINATED BY \u0027,\u0027 tblproperties(\"skip.header.line.count\"\u003d\"1\");\nLOAD DATA INPATH \u0027/sales_data.csv\u0027 INTO TABLE sales_data;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Step 5: Basic Hive Operations\n1. Count the total number of rows in the table by running the command `SELECT COUNT(*) FROM sales_db.sales_data;`.\n\u003cpre\u003e\n\u003cb\u003eResult\u003c/b\u003e\n33\n\u003c/pre\u003e"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT COUNT(*) FROM sales_db.sales_data;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "2. Find the top 3 products by running the command `SELECT product_name, SUM(product_price * quantity) as total_sales FROM sales_db.sales_data GROUP BY product_name ORDER BY total_sales DESC LIMIT 3;`.\n\n\u003cpre\u003e\n\u003cb\u003eResult\u003c/b\u003e\nShirt_B  1033.569990158081\nShirt_A  981.7300338745117\nShirt_C  941.6400108337402\n\u003c/pre\u003e\n"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT product_name, SUM(product_price * quantity) as total_sales FROM sales_db.sales_data GROUP BY product_name ORDER BY total_sales DESC LIMIT 3;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Create a new clean table\n3. Create a new clean table by removing all rows that contain missing values in quantity or product_price by running the command `CREATE TABLE clean_sales AS SELECT * FROM sales_db.sales_data WHERE quantity IS NOT NULL AND product_price IS NOT NULL;`.\n4. Find the number of remaining records in clean_sales by running the command `CREATE TABLE clean_sales AS SELECT * FROM sales_db.clean_sales WHERE quantity IS NOT NULL AND product_price IS NOT NULL;`.\n\u003cpre\u003e\n\u003cb\u003eResult\u003c/b\u003e\n30\n\u003c/pre\u003e\n"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nUSE sales_db;\nCREATE TABLE clean_sales AS SELECT * FROM sales_db.sales_data WHERE quantity IS NOT NULL AND product_price IS NOT NULL;"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT COUNT(*) FROM sales_db.clean_sales;\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Step 6: Hive Aggregation Operations on clean_sales Table\n\n1. Find the total sales by province in order by running the command `SELECT province, SUM(product_price * quantity) as total_sales FROM clean_sales GROUP BY province ORDER BY total_sales DESC;`.\n\n\u003cpre\u003e\n\u003cb\u003eResult\u003c/b\u003e\nBritish Columbia        1243.4999980926514\nQuebec                  1441.3700103759766\nOntario                 1905.3000259399414\n\u003c/pre\u003e\n"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT province, SUM(product_price * quantity) as total_sales FROM clean_sales GROUP BY province ORDER BY total_sales DESC;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n\n2. Find the average price of each product by province by running the command `SELECT province, product_name, AVG(product_price) as avg_price FROM sales_db.clean_sales GROUP BY province, product_name;`.\n\n\u003cpre\u003e\n\u003cb\u003eResult\u003c/b\u003e\nBritish Columbia        Shirt_A     28.489999771118164\nBritish Columbia        Shirt_B     23.989999771118164\nBritish Columbia        Shirt_C     33.49000072479248\nBritish Columbia        Shirt_D     19.489999771118164\nBritish Columbia        Shirt_E     28.49000072479248\nOntario                 Shirt_A     38.4900016784668\nOntario                 Shirt_B     23.989999771118164\nOntario                 Shirt_C     26.99000072479248\nOntario                 Shirt_D     20.989999771118164\nOntario                 Shirt_E     28.49000072479248\nQuebec                  Shirt_A     43.4900016784668\nQuebec                  Shirt_B     23.489999771118164\nQuebec                  Shirt_C     26.99000072479248\nQuebec                  Shirt_D     19.489999771118164\nQuebec                  Shirt_E     28.49000072479248 \n\u003c/pre\u003e"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT province, product_name, AVG(product_price) as avg_price FROM sales_db.clean_sales GROUP BY province, product_name;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n3. Find the total quantity of each product sold in Toronto by running the command `SELECT product_name, SUM(quantity) as total_quantity FROM sales_db.clean_sales WHERE city\u003d\u0027Toronto\u0027 GROUP BY product_name;`.\n\n\u003cpre\u003e\n\u003cb\u003eResult\u003c/b\u003e\nShirt_A   5 \nShirt_B   9 \nShirt_C   4 \nShirt_D   7 \nShirt_E   3\n\u003c/pre\u003e\n"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT product_name, SUM(quantity) as total_quantity FROM sales_db.clean_sales WHERE city\u003d\u0027Toronto\u0027 GROUP BY product_name;\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "4. Find the total sales by city by running the command `SELECT city, SUM(product_price * quantity) as total_sales FROM sales_db.clean_sales GROUP BY city ORDER BY total_sales DESC;`.\n\n\u003cpre\u003e\n\u003cb\u003eResult\u003c/b\u003e\nOttawa          1151.5800151824951\nToronto         753.7200107574463\nMontreal        733.6500091552734\nVancouver       728.6899929046631\nQuebec City     707.7200012207031\nVictoria        514.8100051879883\n\u003c/pre\u003e\n"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT city, SUM(product_price * quantity) as total_sales FROM sales_db.clean_sales GROUP BY city ORDER BY total_sales DESC;\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "5. Find the average price of each product in each city by running the command `SELECT city, product_name, AVG(product_price) as avg_price FROM sales_db.clean_sales GROUP BY city, product_name ORDER BY avg_price DESC;`.\n\n\u003cpre\u003e\n\u003cb\u003eResult\u003c/b\u003e\nQuebec City     Shirt_A       50.9900016784668\nOttawa          Shirt_A       40.9900016784668\nVictoria        Shirt_E       40.9900016784668\nQuebec City     Shirt_E       40.9900016784668\nOttawa          Shirt_E       40.9900016784668\nMontreal        Shirt_A       35.9900016784668\nVictoria        Shirt_C       35.9900016784668\nToronto         Shirt_A       35.9900016784668\nMontreal        Shirt_C       32.9900016784668\nToronto         Shirt_C       32.9900016784668\nVictoria        Shirt_A       30.989999771118164\nVancouver       Shirt_C       30.989999771118164\nVancouver       Shirt_B       28.989999771118164\nToronto         Shirt_B       28.989999771118164\nVancouver       Shirt_A       25.989999771118164\nVictoria        Shirt_D       25.989999771118164\nQuebec City     Shirt_D       25.989999771118164\nMontreal        Shirt_B       25.989999771118164\nOttawa          Shirt_D       22.989999771118164\nOttawa          Shirt_C       20.989999771118164\nQuebec City     Shirt_B       20.989999771118164\nQuebec City     Shirt_C       20.989999771118164\nToronto         Shirt_D       18.989999771118164\nVictoria        Shirt_B       18.989999771118164\nOttawa          Shirt_B       18.989999771118164\nVancouver       Shirt_E       15.989999771118164\nMontreal        Shirt_E       15.989999771118164\nToronto         Shirt_E       15.989999771118164\nVancouver       Shirt_D       12.989999771118164\nMontreal        Shirt_D       12.989999771118164\n\u003c/pre\u003e\n"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT city, product_name, AVG(product_price) as avg_price FROM sales_db.clean_sales GROUP BY city, product_name ORDER BY avg_price DESC;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Step 7: Cleanup\n- Drop the table by running the command `DROP TABLE sales_data;`\n- Drop the database by running the command `DROP DATABASE sales_db;`\n- Once you have finished the lab, you may delete the cluster to avoid incurring additional charges.\n"
    }
  ]
}