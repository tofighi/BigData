{
  "metadata": {
    "name": "Spark_Regression_Happiness",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ""
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Happiness Dataset\nThis is a Regression example for predicting a numerical value. We first need to download Happiness dataset and we are going to predict Happiness rank from Happiness score of a country."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\ncurl https://raw.githubusercontent.com/tofighi/dataset/main/big-data/happiness/happiness_2020.csv --output happiness.csv --silent\nmv happiness.csv  /var/tmp/"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Just a bunch of import statements, you can run these in a paste command\n"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.functions._\r\nimport org.apache.spark.ml.feature.{VectorAssembler}\r\nimport org.apache.spark.ml.Pipeline\r\nimport org.apache.spark.ml.regression.{LinearRegression}\r\nimport org.apache.spark.ml.tuning.{CrossValidator, CrossValidatorModel, ParamGridBuilder}\r\nimport org.apache.spark.ml.evaluation.{RegressionEvaluator}\r\nimport org.apache.spark.ml.param.ParamMap\r\nimport org.apache.spark.sql.types.{DoubleType}"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "-- Loading our CSV file, note the inferSchema option being set to true"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val data \u003d spark.read\r\n .format(\"csv\")\r\n .option(\"sep\", \",\")\r\n .option(\"inferSchema\", \"true\")\r\n .option(\"header\", \"true\")\r\n .load(\"file:///var/tmp/happiness.csv\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "-- Here we are just selecting two columns from our dataset --\u003e The happiness rank and happiness score"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val rank_score \u003d data.select(col(\"Happiness Rank\").cast(DoubleType), col(\"Happiness Score\").cast(DoubleType))"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "rank_score.show(5)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\r\n-- Next we split the dataset into training and test sets\r\n-- We use a randomSplit function with a split percentage of 80%, and 20%\r\n-- The second argument to the function is the seed, it is used to get the same random results every time (for reproducibility of the results)"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val Array(trainingData, testData) \u003d rank_score.randomSplit(Array(0.8, 0.2), seed\u003d1111) "
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Machine Learning Steps\n\n-- All the following steps will be the same for all machine learning problems\n\n-- Preparing features and labels \n\n-- We need to prepare our features and labels to supply it to our algorithm, in this case linear regression\n-- Remember features are the input data to our algorithm and labels are the values our algorithm is going to train the model to predict\n-- Features are also called independent variables\n-- Lables are also called dependent variables\n\n-- In our problem, we only have one FEATURE, it is the happiness score\n-- We will predict the happiness rank, which becomes the LABEL\n\n-- We will pass an array to the InputCols with the name of all the features \n-- And we will simply give the name of the output column\n\n-- Think of a VectorAssembler as an Array\n-- Vector assembler can be used to package one feature or multiple features into a vector\n-- And this will be our features column\n-- We pass an array to inputCols with the name of all the features we want to assemple"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val assembler \u003d new VectorAssembler()\n.setInputCols(Array(\"Happiness Score\"))\n.setOutputCol(\"assembled-features\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\r\n-- Next we will instantiate our algorithm, in this case linear regression, and set the features and label column\r\n-- In this case, the features column will be the output from VectorAssembler which is the assembled features\r\n-- And label is the value linear regression will try to predict which is the happiness rank\r\n-- Features column will be the output form the vector assempler"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val lr \u003d new LinearRegression() \n .setFeaturesCol(\"assembled-features\")\n .setLabelCol(\"Happiness Rank\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "-- Next we create a pipeline for everything that needs to be executed\n-- Think of the pipeline as the assembly line in the factory where all the parts for a product are assembled together\n-- This is what we are doing with pipeline\n-- We create STAGES in pipelines\n-- In this example, our pipeline has only two stages\n-- The first stage is where we assemble the features with VectorAssembler\n-- And the second stage, we\u0027ll specify the algorithm that is used to train the model\n"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nval pipeline \u003d new Pipeline()\n .setStages(Array(assembler, lr))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "-- Once we train the model, we need to evaluate the model for accuracy\n-- Since this is a regression problem, we will use RegressionEvaluator to evaluate the model\n-- The model, once it performs the predictions, it will store the prediction results in the predition column\n-- Once a prediction is made, we need to evalue the prediction with the actual value, so we know how good the prediction is\n-- So in our case, our model will predict the ranking based on our score\n-- We need to see if the the prediction matches the actual or not\n-- If it doesn\u0027t match, we want to know how far the prediction is from the actual value\n-- We will use a metric called r squared to show the accuracy of the model prediction\n-- r squared is also called coefficient of determination\n-- r squared basically tells us how good our model is \n-- The higher the r2 model the better our model\n-- r2 is a value between 0 and 1, and as much as it is closer to 1 it is better)"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\r\nval evaluator \u003d new RegressionEvaluator()\r\n .setLabelCol(\"Happiness Rank\")\r\n .setPredictionCol(\"prediction\")\r\n .setMetricName(\"r2\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "-- Next we setup our cross validator\n-- cross validator is an interesting concept\n-- We need to provide two things to the CrossValidator\n-- An estimator and an evaluator\n-- Estimator we provide the pipeline\n-- For the evaluator we provide regression evaluator \n-- We can provide additinoal parameters called \"hyper parameters\" which can be used for tuning our model\n-- We don\u0027t have any hyper parameters so we create an instance of the parameter Grid Builder and call the build method\n-- This will provide an empty parameter map\n-- Finally we specify the fold as 3\n-- This means the cross validator will generate three sets of data from our initial training dataset\n-- In other words it \"folds\" the data into 3 and from each sets of data, it will use 2/3 of the data for training and 1/3 of the data for testing\n-- And then it will fix the model based on the best accuracy based on the defined evaluation metric, in our case r2"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\r\nval cross_validator \u003d new CrossValidator()\r\n .setEstimator(pipeline)\r\n .setEvaluator(evaluator)\r\n .setEstimatorParamMaps(new ParamGridBuilder().build)\r\n .setNumFolds(3)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "-- Next we call fit on the cross validator passing our trainig dataset\n-- CrossValidator will now fold the dataset into 3, divide each subset into training and test set\n-- Inside each fold, it will use the training set to train and test set to evaluate the model based on r2\n-- The best of the three models is returned "
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nval cvModel \u003d cross_validator.fit(trainingData)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\r\n-- Now cvModel is a trained model that we can use to make predictions\r\n-- We can actually save this model and reuse it as well\r\n-- We\u0027ll see how to do that later\r\n\r\n-- Before we can use our model on the real data, let\u0027s test our data on the real data to see how good it is\r\n-- We now called cvModel.transform on the testData set\r\n-- when we call transform, our model will go over the dataset and make predictions"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nval predictions \u003d cvModel.transform(testData)"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\npredictions.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "-- Remember, the directory SHOULD NOT EXIST, remove it first if it does\n-- On HDFS:\nhadoop fs -rm -r /BigData/happiness/output/\n-- On local:\nrm -r /var/tmp/output\n-- Once the model has made predictions, we are just selecting the \"Happiness Rank\", \"Happiness Socre\" and the prediction column from the model\n-- and write it as a CSV file in a location in HDFS"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\nrm -r /var/tmp/output"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\nls /var/tmp"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "predictions\n .select(col(\"Happiness Rank\"), col(\"Happiness Score\"), col(\"prediction\"))\n .write\n .format(\"csv\")\n .save(\"file:///var/tmp/output1\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "-- Finally, we call the evaluator method on the evaluator passing the preditions DataFrame\n-- It will give us back the r2 result\n-- R2 is presented as a percentage, if we get 0.9, means our model is 90% accurate"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nval r2 \u003d evaluator.evaluate(predictions)\nprintln(\"r-squared on test data \u003d \" + r2)"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n"
    }
  ]
}